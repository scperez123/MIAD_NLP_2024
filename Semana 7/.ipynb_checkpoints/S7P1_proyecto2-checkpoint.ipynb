{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 2 - Clasificación de género de películas\n",
    "\n",
    "El propósito de este proyecto es que puedan poner en práctica, en sus respectivos grupos de trabajo, sus conocimientos sobre técnicas de preprocesamiento, modelos predictivos de NLP, y la disponibilización de modelos. Para su desarrollo tengan en cuenta las instrucciones dadas en la \"Guía del proyecto 2: Clasificación de género de películas\"\n",
    "\n",
    "**Entrega**: La entrega del proyecto deberán realizarla durante la semana 8. Sin embargo, es importante que avancen en la semana 7 en el modelado del problema y en parte del informe, tal y como se les indicó en la guía.\n",
    "\n",
    "Para hacer la entrega, deberán adjuntar el informe autocontenido en PDF a la actividad de entrega del proyecto que encontrarán en la semana 8, y subir el archivo de predicciones a la [competencia de Kaggle](https://www.kaggle.com/t/2c54d005f76747fe83f77fbf8b3ec232)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos para la predicción de género en películas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/moviegenre.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este proyecto se usará un conjunto de datos de géneros de películas. Cada observación contiene el título de una película, su año de lanzamiento, la sinopsis o plot de la película (resumen de la trama) y los géneros a los que pertenece (una película puede pertenercer a más de un género). Por ejemplo:\n",
    "- Título: 'How to Be a Serial Killer'\n",
    "- Plot: 'A serial killer decides to teach the secrets of his satisfying career to a video store clerk.'\n",
    "- Generos: 'Comedy', 'Crime', 'Horror'\n",
    "\n",
    "La idea es que usen estos datos para predecir la probabilidad de que una película pertenezca, dada la sinopsis, a cada uno de los géneros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agradecemos al profesor Fabio González, Ph.D. y a su alumno John Arevalo por proporcionar este conjunto de datos. Ver https://arxiv.org/abs/1702.01992"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo predicción conjunto de test para envío a Kaggle\n",
    "En esta sección encontrarán el formato en el que deben guardar los resultados de la predicción para que puedan subirlos a la competencia en Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T16:48:29.338285Z",
     "start_time": "2024-05-25T16:48:29.332783Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T16:48:30.872935Z",
     "start_time": "2024-05-25T16:48:29.438977Z"
    }
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\perezs5\\documents\\ana\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade tensorflow\n",
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T01:13:13.748472Z",
     "start_time": "2024-05-26T01:13:13.742621Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense, Input\n",
    "#from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "#from tensorflow.keras import backend as K\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T02:00:04.118746Z",
     "start_time": "2024-05-26T02:00:01.449392Z"
    }
   },
   "outputs": [],
   "source": [
    "# Carga de datos de archivo .csv\n",
    "dataTraining = pd.read_csv('https://github.com/albahnsen/MIAD_ML_and_NLP/raw/main/datasets/dataTraining.zip', encoding='UTF-8', index_col=0)\n",
    "dataTesting = pd.read_csv('https://github.com/albahnsen/MIAD_ML_and_NLP/raw/main/datasets/dataTesting.zip', encoding='UTF-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T02:00:04.130656Z",
     "start_time": "2024-05-26T02:00:04.120442Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>2003</td>\n",
       "      <td>Most</td>\n",
       "      <td>most is the story of a single father who takes...</td>\n",
       "      <td>['Short', 'Drama']</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>2008</td>\n",
       "      <td>How to Be a Serial Killer</td>\n",
       "      <td>a serial killer decides to teach the secrets o...</td>\n",
       "      <td>['Comedy', 'Crime', 'Horror']</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6724</th>\n",
       "      <td>1941</td>\n",
       "      <td>A Woman's Face</td>\n",
       "      <td>in sweden ,  a female blackmailer with a disfi...</td>\n",
       "      <td>['Drama', 'Film-Noir', 'Thriller']</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4704</th>\n",
       "      <td>1954</td>\n",
       "      <td>Executive Suite</td>\n",
       "      <td>in a friday afternoon in new york ,  the presi...</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>1990</td>\n",
       "      <td>Narrow Margin</td>\n",
       "      <td>in los angeles ,  the editor of a publishing h...</td>\n",
       "      <td>['Action', 'Crime', 'Thriller']</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year                      title  \\\n",
       "3107  2003                       Most   \n",
       "900   2008  How to Be a Serial Killer   \n",
       "6724  1941             A Woman's Face   \n",
       "4704  1954            Executive Suite   \n",
       "2582  1990              Narrow Margin   \n",
       "\n",
       "                                                   plot  \\\n",
       "3107  most is the story of a single father who takes...   \n",
       "900   a serial killer decides to teach the secrets o...   \n",
       "6724  in sweden ,  a female blackmailer with a disfi...   \n",
       "4704  in a friday afternoon in new york ,  the presi...   \n",
       "2582  in los angeles ,  the editor of a publishing h...   \n",
       "\n",
       "                                  genres  rating  \n",
       "3107                  ['Short', 'Drama']     8.0  \n",
       "900        ['Comedy', 'Crime', 'Horror']     5.6  \n",
       "6724  ['Drama', 'Film-Noir', 'Thriller']     7.2  \n",
       "4704                           ['Drama']     7.4  \n",
       "2582     ['Action', 'Crime', 'Thriller']     6.6  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualización datos de entrenamiento\n",
    "dataTraining.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T02:00:04.140984Z",
     "start_time": "2024-05-26T02:00:04.132218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>Message in a Bottle</td>\n",
       "      <td>who meets by fate ,  shall be sealed by fate ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1978</td>\n",
       "      <td>Midnight Express</td>\n",
       "      <td>the true story of billy hayes ,  an american c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1996</td>\n",
       "      <td>Primal Fear</td>\n",
       "      <td>martin vail left the chicago da ' s office to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1950</td>\n",
       "      <td>Crisis</td>\n",
       "      <td>husband and wife americans dr .  eugene and mr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1959</td>\n",
       "      <td>The Tingler</td>\n",
       "      <td>the coroner and scientist dr .  warren chapin ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                title  \\\n",
       "1  1999  Message in a Bottle   \n",
       "4  1978     Midnight Express   \n",
       "5  1996          Primal Fear   \n",
       "6  1950               Crisis   \n",
       "7  1959          The Tingler   \n",
       "\n",
       "                                                plot  \n",
       "1  who meets by fate ,  shall be sealed by fate ....  \n",
       "4  the true story of billy hayes ,  an american c...  \n",
       "5  martin vail left the chicago da ' s office to ...  \n",
       "6  husband and wife americans dr .  eugene and mr...  \n",
       "7  the coroner and scientist dr .  warren chapin ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualización datos de test\n",
    "dataTesting.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T02:00:04.760702Z",
     "start_time": "2024-05-26T02:00:04.143071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7895, 1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de variables predictoras (X)\n",
    "vect = CountVectorizer(max_features=1000)\n",
    "X_dtm = vect.fit_transform(dataTraining['plot'])\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T02:00:08.340916Z",
     "start_time": "2024-05-26T02:00:08.265845Z"
    }
   },
   "outputs": [],
   "source": [
    "# Definición de variable de interés (y)\n",
    "dataTraining['genres'] = dataTraining['genres'].map(lambda x: eval(x))\n",
    "le = MultiLabelBinarizer()\n",
    "y_genres = le.fit_transform(dataTraining['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T02:00:09.065190Z",
     "start_time": "2024-05-26T02:00:09.023817Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "scaler.fit(X_dtm)\n",
    "X_train, X_test, y_train_genres, y_test_genres = train_test_split(X_dtm, y_genres, test_size=0.33, random_state=42)\n",
    "#X_train = pd.DataFrame(data=scaler.transform(X_train))\n",
    "#X_test = pd.DataFrame(data=scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:53:47.643978Z",
     "start_time": "2024-05-25T18:53:43.630666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=RandomForestClassifier(max_depth=10, n_jobs=-1,\n",
       "                                                     random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=RandomForestClassifier(max_depth=10, n_jobs=-1,\n",
       "                                                     random_state=42))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, n_jobs=-1, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=RandomForestClassifier(max_depth=10, n_jobs=-1,\n",
       "                                                     random_state=42))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición y entrenamiento\n",
    "clf = OneVsRestClassifier(RandomForestClassifier(n_jobs=-1, n_estimators=100, max_depth=10, random_state=42))\n",
    "clf.fit(X_train, y_train_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:53:49.335157Z",
     "start_time": "2024-05-25T18:53:48.591078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7812262183677007"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicción del modelo de clasificación\n",
    "y_pred_genres = clf.predict_proba(X_test)\n",
    "\n",
    "# Impresión del desempeño del modelo\n",
    "roc_auc_score(y_test_genres, y_pred_genres, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:53:49.340302Z",
     "start_time": "2024-05-25T18:53:49.336173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:53:50.785039Z",
     "start_time": "2024-05-25T18:53:49.727798Z"
    }
   },
   "outputs": [],
   "source": [
    "# transformación variables predictoras X del conjunto de test\n",
    "X_test_dtm = vect.transform(dataTesting['plot'])\n",
    "\n",
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "# Predicción del conjunto de test\n",
    "y_pred_test_genres = clf.predict_proba(X_test_dtm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:53:50.869445Z",
     "start_time": "2024-05-25T18:53:50.786576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_Action</th>\n",
       "      <th>p_Adventure</th>\n",
       "      <th>p_Animation</th>\n",
       "      <th>p_Biography</th>\n",
       "      <th>p_Comedy</th>\n",
       "      <th>p_Crime</th>\n",
       "      <th>p_Documentary</th>\n",
       "      <th>p_Drama</th>\n",
       "      <th>p_Family</th>\n",
       "      <th>p_Fantasy</th>\n",
       "      <th>...</th>\n",
       "      <th>p_Musical</th>\n",
       "      <th>p_Mystery</th>\n",
       "      <th>p_News</th>\n",
       "      <th>p_Romance</th>\n",
       "      <th>p_Sci-Fi</th>\n",
       "      <th>p_Short</th>\n",
       "      <th>p_Sport</th>\n",
       "      <th>p_Thriller</th>\n",
       "      <th>p_War</th>\n",
       "      <th>p_Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.143030</td>\n",
       "      <td>0.101960</td>\n",
       "      <td>0.024454</td>\n",
       "      <td>0.029938</td>\n",
       "      <td>0.354552</td>\n",
       "      <td>0.138830</td>\n",
       "      <td>0.030787</td>\n",
       "      <td>0.490140</td>\n",
       "      <td>0.073159</td>\n",
       "      <td>0.101339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025069</td>\n",
       "      <td>0.063208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362818</td>\n",
       "      <td>0.056648</td>\n",
       "      <td>0.008970</td>\n",
       "      <td>0.017522</td>\n",
       "      <td>0.202605</td>\n",
       "      <td>0.033989</td>\n",
       "      <td>0.018117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.122624</td>\n",
       "      <td>0.085786</td>\n",
       "      <td>0.024213</td>\n",
       "      <td>0.084795</td>\n",
       "      <td>0.370949</td>\n",
       "      <td>0.216657</td>\n",
       "      <td>0.080359</td>\n",
       "      <td>0.515684</td>\n",
       "      <td>0.062976</td>\n",
       "      <td>0.067019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>0.060935</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.149703</td>\n",
       "      <td>0.058190</td>\n",
       "      <td>0.014248</td>\n",
       "      <td>0.020099</td>\n",
       "      <td>0.204794</td>\n",
       "      <td>0.030438</td>\n",
       "      <td>0.018506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.151364</td>\n",
       "      <td>0.110284</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>0.075334</td>\n",
       "      <td>0.304837</td>\n",
       "      <td>0.448736</td>\n",
       "      <td>0.021010</td>\n",
       "      <td>0.611544</td>\n",
       "      <td>0.081741</td>\n",
       "      <td>0.169121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044538</td>\n",
       "      <td>0.261372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335987</td>\n",
       "      <td>0.128505</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.048658</td>\n",
       "      <td>0.423242</td>\n",
       "      <td>0.052693</td>\n",
       "      <td>0.025351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.154448</td>\n",
       "      <td>0.125772</td>\n",
       "      <td>0.020991</td>\n",
       "      <td>0.064124</td>\n",
       "      <td>0.340779</td>\n",
       "      <td>0.140892</td>\n",
       "      <td>0.009133</td>\n",
       "      <td>0.632038</td>\n",
       "      <td>0.068287</td>\n",
       "      <td>0.063631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131074</td>\n",
       "      <td>0.088418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197224</td>\n",
       "      <td>0.132208</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.039743</td>\n",
       "      <td>0.269385</td>\n",
       "      <td>0.077607</td>\n",
       "      <td>0.017862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.175143</td>\n",
       "      <td>0.210069</td>\n",
       "      <td>0.035476</td>\n",
       "      <td>0.032505</td>\n",
       "      <td>0.313850</td>\n",
       "      <td>0.243150</td>\n",
       "      <td>0.021793</td>\n",
       "      <td>0.427885</td>\n",
       "      <td>0.079781</td>\n",
       "      <td>0.143879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023859</td>\n",
       "      <td>0.090359</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.205117</td>\n",
       "      <td>0.241663</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.018403</td>\n",
       "      <td>0.259465</td>\n",
       "      <td>0.021569</td>\n",
       "      <td>0.017585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   p_Action  p_Adventure  p_Animation  p_Biography  p_Comedy   p_Crime  \\\n",
       "1  0.143030     0.101960     0.024454     0.029938  0.354552  0.138830   \n",
       "4  0.122624     0.085786     0.024213     0.084795  0.370949  0.216657   \n",
       "5  0.151364     0.110284     0.013762     0.075334  0.304837  0.448736   \n",
       "6  0.154448     0.125772     0.020991     0.064124  0.340779  0.140892   \n",
       "7  0.175143     0.210069     0.035476     0.032505  0.313850  0.243150   \n",
       "\n",
       "   p_Documentary   p_Drama  p_Family  p_Fantasy  ...  p_Musical  p_Mystery  \\\n",
       "1       0.030787  0.490140  0.073159   0.101339  ...   0.025069   0.063208   \n",
       "4       0.080359  0.515684  0.062976   0.067019  ...   0.024734   0.060935   \n",
       "5       0.021010  0.611544  0.081741   0.169121  ...   0.044538   0.261372   \n",
       "6       0.009133  0.632038  0.068287   0.063631  ...   0.131074   0.088418   \n",
       "7       0.021793  0.427885  0.079781   0.143879  ...   0.023859   0.090359   \n",
       "\n",
       "     p_News  p_Romance  p_Sci-Fi   p_Short   p_Sport  p_Thriller     p_War  \\\n",
       "1  0.000000   0.362818  0.056648  0.008970  0.017522    0.202605  0.033989   \n",
       "4  0.000477   0.149703  0.058190  0.014248  0.020099    0.204794  0.030438   \n",
       "5  0.000000   0.335987  0.128505  0.001016  0.048658    0.423242  0.052693   \n",
       "6  0.000000   0.197224  0.132208  0.001432  0.039743    0.269385  0.077607   \n",
       "7  0.000048   0.205117  0.241663  0.002634  0.018403    0.259465  0.021569   \n",
       "\n",
       "   p_Western  \n",
       "1   0.018117  \n",
       "4   0.018506  \n",
       "5   0.025351  \n",
       "6   0.017862  \n",
       "7   0.017585  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar predicciones en formato exigido en la competencia de kaggle\n",
    "\n",
    "res = pd.DataFrame(y_pred_test_genres, index=dataTesting.index, columns=cols)\n",
    "res.to_csv('pred_genres_text_RF.csv', index_label='ID')\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desarrollo Proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:04:34.584841Z",
     "start_time": "2024-05-25T20:04:34.523133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24  output variables\n",
      "1000 input variables\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_var = y_train_genres.shape[1]\n",
    "print(output_var, ' output variables')\n",
    "dims = X_train.shape[1]\n",
    "print(dims, 'input variables')\n",
    "dense_shape = X_train.shape\n",
    "indices = np.column_stack(X_train.nonzero())\n",
    "values = X_train.data\n",
    "X_train_sparse = tf.sparse.SparseTensor(\n",
    "    indices=indices,\n",
    "    values=values,\n",
    "    dense_shape=dense_shape\n",
    ")\n",
    "X_train_sparse_ordered = tf.sparse.reorder(X_train_sparse)\n",
    "X_train_dense = tf.sparse.to_dense(X_train_sparse_ordered).numpy()\n",
    "X_train2, X_val, Y_train2, Y_val = train_test_split(X_train_dense, y_train_genres, test_size=0.15, random_state=42)\n",
    "def nn_model_params(optimizer ,\n",
    "                    neurons,\n",
    "                    batch_size,\n",
    "                    epochs,\n",
    "                    activation,\n",
    "                    patience,\n",
    "                    loss):\n",
    "    \n",
    "    K.clear_session()\n",
    "\n",
    "    # Definición red neuronal con la función Sequential()\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Definición de las capas de la red con el número de neuronas y la función de activación definidos en la función nn_model_params\n",
    "    model.add(Dense(neurons, input_shape=(dims,), activation=activation))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(output_var, activation=activation))\n",
    "\n",
    "    # Definición de función de perdida con parámetros definidos en la función nn_model_params\n",
    "    model.compile(optimizer = optimizer, loss=loss)\n",
    "    \n",
    "    # Definición de la función EarlyStopping con parámetro definido en la función nn_model_params\n",
    "    early_stopping = EarlyStopping(monitor=\"val_loss\", patience = patience)\n",
    "\n",
    "    # Entrenamiento de la red neuronal con parámetros definidos en la función nn_model_params\n",
    "    model.fit(X_train2, Y_train2,\n",
    "              validation_data = (X_val, Y_val),\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              callbacks=[early_stopping, PlotLossesKeras()],\n",
    "              verbose=True\n",
    "              )\n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:04:36.267771Z",
     "start_time": "2024-05-25T20:04:36.264620Z"
    }
   },
   "outputs": [],
   "source": [
    "nn_params = {\n",
    "    'optimizer': ['adam','sgd'],\n",
    "    'activation': ['relu','sigmoid','softmax'],\n",
    "    'batch_size': [64,512],\n",
    "    'neurons':[64,512],\n",
    "    'epochs':[20,50],\n",
    "    'patience':[2,5],\n",
    "    'loss':['mean_squared_error','binary_crossentropy','categorical_crossentropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método busqueda por cuadrícula (Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KerasRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nn_model \u001b[38;5;241m=\u001b[39m KerasRegressor(build_fn\u001b[38;5;241m=\u001b[39mnn_model_params)\n\u001b[0;32m      2\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSearchCV(nn_model, nn_params, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      4\u001b[0m gs\u001b[38;5;241m.\u001b[39mfit(X_train2, Y_train2)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KerasRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "nn_model = KerasRegressor(build_fn=nn_model_params)\n",
    "gs = GridSearchCV(nn_model, nn_params, cv=3)\n",
    "\n",
    "gs.fit(X_train2, Y_train2)\n",
    "\n",
    "print('Los mejores parametros segun Grid Search:', gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'K' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m nn_model_params(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, neurons\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[27], line 24\u001b[0m, in \u001b[0;36mnn_model_params\u001b[1;34m(optimizer, neurons, batch_size, epochs, activation, patience, loss)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnn_model_params\u001b[39m(optimizer ,\n\u001b[0;32m     17\u001b[0m                     neurons,\n\u001b[0;32m     18\u001b[0m                     batch_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m                     patience,\n\u001b[0;32m     22\u001b[0m                     loss):\n\u001b[1;32m---> 24\u001b[0m     K\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# Definición red neuronal con la función Sequential()\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     model \u001b[38;5;241m=\u001b[39m Sequential()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'K' is not defined"
     ]
    }
   ],
   "source": [
    "model = nn_model_params(optimizer='adam', neurons=512, batch_size=64, epochs=50, activation='relu', patience=5, loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T02:00:37.062874Z",
     "start_time": "2024-05-26T02:00:36.903849Z"
    }
   },
   "outputs": [],
   "source": [
    "dense_shape = X_test.shape\n",
    "indices = np.column_stack(X_test.nonzero())\n",
    "values = X_test.data\n",
    "X_test_sparse = tf.sparse.SparseTensor(\n",
    "    indices=indices,\n",
    "    values=values,\n",
    "    dense_shape=dense_shape\n",
    ")\n",
    "X_test_sparse_ordered = tf.sparse.reorder(X_test_sparse)\n",
    "X_test_dense = tf.sparse.to_dense(X_test_sparse_ordered).numpy()\n",
    "Y_predict_neuronal = model.predict(X_test_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T02:00:37.087076Z",
     "start_time": "2024-05-26T02:00:37.064100Z"
    }
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y_test_genres, Y_predict_neuronal, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T02:00:40.752968Z",
     "start_time": "2024-05-26T02:00:40.132837Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_dtm = vect.transform(dataTesting['plot'])\n",
    "dense_shape = X_test_dtm.shape\n",
    "indices = np.column_stack(X_test_dtm.nonzero())\n",
    "values = X_test_dtm.data\n",
    "X_test_dtm_sparse = tf.sparse.SparseTensor(\n",
    "    indices=indices,\n",
    "    values=values,\n",
    "    dense_shape=dense_shape\n",
    ")\n",
    "X_test_dtm_sparse_ordered = tf.sparse.reorder(X_test_dtm_sparse)\n",
    "X_test_dtm_dense = tf.sparse.to_dense(X_test_dtm_sparse_ordered).numpy()\n",
    "Y_predict_neuronal = model.predict(X_test_dtm_dense)\n",
    "# Predicción del conjunto de test\n",
    "res = pd.DataFrame(Y_predict_neuronal, index=dataTesting.index, columns=cols)\n",
    "res.to_csv('pred_genres_neuronal.csv', index_label='ID')\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este caso se realizo el entrenamiento de una red neuronal en la cual en primer lugar se realizo el estandarizado de los datos con el proposito de que todos tuvieran la misma dimensionalidad para despues  calibrar los hiperparametros usando GridSearchCV en donde se obtuvieron los siguientes parametros : {'activation': 'relu', 'batch_size': 64, 'epochs': 50, 'loss': 'mean_squared_error', 'neurons': 512, 'optimizer': 'adam', 'patience': 5} en donde despues se prosigue a evaluar su poder predictivo en donde nos da un roc de 0.6 en donde el modelo presenta un poder predictivo bajo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo metodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T01:00:08.144211Z",
     "start_time": "2024-05-26T01:00:08.137730Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\perezs5\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\perezs5\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T01:00:15.387418Z",
     "start_time": "2024-05-26T01:00:13.395449Z"
    }
   },
   "outputs": [],
   "source": [
    "dataTraining = pd.read_csv('https://github.com/albahnsen/MIAD_ML_and_NLP/raw/main/datasets/dataTraining.zip', encoding='UTF-8', index_col=0)\n",
    "dataTesting = pd.read_csv('https://github.com/albahnsen/MIAD_ML_and_NLP/raw/main/datasets/dataTesting.zip', encoding='UTF-8', index_col=0)\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "dataTraining['genres'] = dataTraining['genres'].map(lambda x: eval(x))\n",
    "dataTraining.dropna(subset=['plot'], inplace=True)\n",
    "dataTesting.dropna(subset=['plot'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T01:00:16.051860Z",
     "start_time": "2024-05-26T01:00:16.047481Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\b\\w{1,2}\\b', '', text)  # Remover palabras cortas\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remover puntuación\n",
    "    text = text.lower()\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T01:13:13.740859Z",
     "start_time": "2024-05-26T01:03:32.542732Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\perezs5\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\perezs5\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\perezs5\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.8443\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_Action</th>\n",
       "      <th>p_Adventure</th>\n",
       "      <th>p_Animation</th>\n",
       "      <th>p_Biography</th>\n",
       "      <th>p_Comedy</th>\n",
       "      <th>p_Crime</th>\n",
       "      <th>p_Documentary</th>\n",
       "      <th>p_Drama</th>\n",
       "      <th>p_Family</th>\n",
       "      <th>p_Fantasy</th>\n",
       "      <th>...</th>\n",
       "      <th>p_Musical</th>\n",
       "      <th>p_Mystery</th>\n",
       "      <th>p_News</th>\n",
       "      <th>p_Romance</th>\n",
       "      <th>p_Sci-Fi</th>\n",
       "      <th>p_Short</th>\n",
       "      <th>p_Sport</th>\n",
       "      <th>p_Thriller</th>\n",
       "      <th>p_War</th>\n",
       "      <th>p_Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.092402</td>\n",
       "      <td>0.084652</td>\n",
       "      <td>0.012940</td>\n",
       "      <td>0.035859</td>\n",
       "      <td>0.250526</td>\n",
       "      <td>0.063461</td>\n",
       "      <td>0.008995</td>\n",
       "      <td>0.563048</td>\n",
       "      <td>0.038448</td>\n",
       "      <td>0.129786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011297</td>\n",
       "      <td>0.059565</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.641219</td>\n",
       "      <td>0.049179</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.008198</td>\n",
       "      <td>0.249507</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>0.003297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.111633</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>0.130590</td>\n",
       "      <td>0.299000</td>\n",
       "      <td>0.373507</td>\n",
       "      <td>0.036538</td>\n",
       "      <td>0.720126</td>\n",
       "      <td>0.012663</td>\n",
       "      <td>0.015727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030510</td>\n",
       "      <td>0.049601</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.048189</td>\n",
       "      <td>0.035659</td>\n",
       "      <td>0.010540</td>\n",
       "      <td>0.014539</td>\n",
       "      <td>0.135603</td>\n",
       "      <td>0.014654</td>\n",
       "      <td>0.011281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.104538</td>\n",
       "      <td>0.028352</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.013698</td>\n",
       "      <td>0.153403</td>\n",
       "      <td>0.895682</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.782740</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>0.046089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.703880</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.159485</td>\n",
       "      <td>0.021397</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.014431</td>\n",
       "      <td>0.523088</td>\n",
       "      <td>0.016002</td>\n",
       "      <td>0.001365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.075964</td>\n",
       "      <td>0.050919</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.057074</td>\n",
       "      <td>0.099848</td>\n",
       "      <td>0.080855</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.693180</td>\n",
       "      <td>0.037175</td>\n",
       "      <td>0.019650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>0.131353</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.254997</td>\n",
       "      <td>0.052519</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.014590</td>\n",
       "      <td>0.257001</td>\n",
       "      <td>0.074340</td>\n",
       "      <td>0.024038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.097777</td>\n",
       "      <td>0.060696</td>\n",
       "      <td>0.005795</td>\n",
       "      <td>0.039584</td>\n",
       "      <td>0.189369</td>\n",
       "      <td>0.046483</td>\n",
       "      <td>0.004461</td>\n",
       "      <td>0.138044</td>\n",
       "      <td>0.093255</td>\n",
       "      <td>0.378920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015328</td>\n",
       "      <td>0.032513</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.042444</td>\n",
       "      <td>0.891800</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0.140894</td>\n",
       "      <td>0.028046</td>\n",
       "      <td>0.028572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   p_Action  p_Adventure  p_Animation  p_Biography  p_Comedy   p_Crime  \\\n",
       "1  0.092402     0.084652     0.012940     0.035859  0.250526  0.063461   \n",
       "4  0.111633     0.011719     0.007698     0.130590  0.299000  0.373507   \n",
       "5  0.104538     0.028352     0.001959     0.013698  0.153403  0.895682   \n",
       "6  0.075964     0.050919     0.001829     0.057074  0.099848  0.080855   \n",
       "7  0.097777     0.060696     0.005795     0.039584  0.189369  0.046483   \n",
       "\n",
       "   p_Documentary   p_Drama  p_Family  p_Fantasy  ...  p_Musical  p_Mystery  \\\n",
       "1       0.008995  0.563048  0.038448   0.129786  ...   0.011297   0.059565   \n",
       "4       0.036538  0.720126  0.012663   0.015727  ...   0.030510   0.049601   \n",
       "5       0.003289  0.782740  0.003807   0.046089  ...   0.004880   0.703880   \n",
       "6       0.001344  0.693180  0.037175   0.019650  ...   0.022400   0.131353   \n",
       "7       0.004461  0.138044  0.093255   0.378920  ...   0.015328   0.032513   \n",
       "\n",
       "     p_News  p_Romance  p_Sci-Fi   p_Short   p_Sport  p_Thriller     p_War  \\\n",
       "1  0.000027   0.641219  0.049179  0.001708  0.008198    0.249507  0.003604   \n",
       "4  0.000169   0.048189  0.035659  0.010540  0.014539    0.135603  0.014654   \n",
       "5  0.000057   0.159485  0.021397  0.000181  0.014431    0.523088  0.016002   \n",
       "6  0.000028   0.254997  0.052519  0.000857  0.014590    0.257001  0.074340   \n",
       "7  0.000026   0.042444  0.891800  0.002538  0.004779    0.140894  0.028046   \n",
       "\n",
       "   p_Western  \n",
       "1   0.003297  \n",
       "4   0.011281  \n",
       "5   0.001365  \n",
       "6   0.024038  \n",
       "7   0.028572  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Descarga los recursos necesarios de NLTK\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Define el conjunto de stopwords y el lematizador\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define la función para limpiar el texto\n",
    "def clean_text(text):\n",
    "    # Elimina palabras con menos de 3 caracteres\n",
    "    text = re.sub(r'\\b\\w{1,2}\\b', '', text)\n",
    "    # Convierte el texto a minúsculas\n",
    "    text = text.lower()\n",
    "    # Elimina caracteres no alfabéticos\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Elimina stopwords y lematiza las palabras restantes\n",
    "    text = ' '.join(lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "# Aplica la función clean_text a las columnas 'plot'\n",
    "dataTraining['clean_plot'] = dataTraining['plot'].apply(clean_text)\n",
    "dataTesting['clean_plot'] = dataTesting['plot'].apply(clean_text)\n",
    "\n",
    "# Vectorización del texto (usando TF-IDF)\n",
    "vect = TfidfVectorizer(max_features=1000)\n",
    "X_dtm = vect.fit_transform(dataTraining['clean_plot'])\n",
    "\n",
    "# Añadir característica adicional: año de lanzamiento\n",
    "X_additional = dataTraining[['year']].values\n",
    "scaler = StandardScaler()\n",
    "X_additional = scaler.fit_transform(X_additional)\n",
    "\n",
    "# Concatenar las características\n",
    "X = np.hstack((X_dtm.toarray(), X_additional))\n",
    "\n",
    "# Binariza las etiquetas de género\n",
    "le = MultiLabelBinarizer()\n",
    "y_genres = le.fit_transform(dataTraining['genres'])\n",
    "\n",
    "# División en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train_genres, y_test_genres = train_test_split(X, y_genres, test_size=0.33, random_state=42)\n",
    "\n",
    "# Definición del modelo\n",
    "clf = OneVsRestClassifier(XGBClassifier(n_jobs=-1, random_state=42))\n",
    "\n",
    "# Parámetros para GridSearchCV\n",
    "param_grid = {\n",
    "    'estimator__max_depth': [3, 5],\n",
    "    'estimator__n_estimators': [100, 200],\n",
    "    'estimator__learning_rate': [0.1, 0.01]\n",
    "}\n",
    "\n",
    "# Búsqueda de hiperparámetros con GridSearchCV\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train_genres)\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Predicción del modelo optimizado\n",
    "y_pred_genres = best_clf.predict_proba(X_test)\n",
    "\n",
    "# Evaluación del desempeño del modelo\n",
    "score = roc_auc_score(y_test_genres, y_pred_genres, average='macro')\n",
    "print(f'ROC AUC Score: {score:.4f}')\n",
    "\n",
    "# Transformación de las variables predictoras del conjunto de test\n",
    "X_test_dtm = vect.transform(dataTesting['clean_plot'])\n",
    "X_test_additional = scaler.transform(dataTesting[['year']].values)\n",
    "X_test_final = np.hstack((X_test_dtm.toarray(), X_test_additional))\n",
    "\n",
    "# Predicción del conjunto de test\n",
    "y_pred_test_genres = best_clf.predict_proba(X_test_final)\n",
    "\n",
    "res = pd.DataFrame(y_pred_test_genres, index=dataTesting.index, columns=cols)\n",
    "res.to_csv('pred_genres_text_optimized.csv', index_label='ID')\n",
    "res.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se realiza un modelo con XGBClassifier en el cual se obtiene un Roc de 0.84 demostrando un mejor poder predictivo que la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regresion.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "modelo = XGBClassifier()\n",
    "modelo.fit(X_train, y_train_genres)\n",
    "joblib.dump(modelo, 'regresion.pkl', compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_additional = scaler.fit_transform(X_additional)\n",
    "\n",
    "# Guardar el scaler entrenado en un archivo pkl\n",
    "joblib.dump(scaler, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elegir el vectorizador (CountVectorizer o TfidfVectorizer)\n",
    "vect = TfidfVectorizer(max_features=1000)  # Puedes ajustar max_features según tus necesidades\n",
    "\n",
    "# Ajustar y transformar los datos de entrenamiento\n",
    "X_dtm = vect.fit_transform(dataTraining['clean_plot'])\n",
    "\n",
    "# Guardar el vectorizador entrenado en un archivo pkl\n",
    "joblib.dump(vect, 'vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_binarizer.pkl']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Binariza las etiquetas de género\n",
    "le = MultiLabelBinarizer()\n",
    "y_genres = le.fit_transform(dataTraining['genres'])\n",
    "\n",
    "\n",
    "# Guardar el codificador de etiquetas\n",
    "joblib.dump(le, 'label_binarizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://10.181.203.70:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "from flask_restx import Api, Resource\n",
    "import joblib\n",
    "from flask_cors import CORS\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "api = Api(app)\n",
    "\n",
    "parser = api.parser()\n",
    "parser.add_argument('year', type=int, required=True, help='year', location='args')\n",
    "parser.add_argument('title', type=str, required=True, help='title', location='args')\n",
    "parser.add_argument('plot', type=str, required=True, help='Plot', location='args')\n",
    "\n",
    "# Cargar los modelos entrenados y el vectorizador\n",
    "vectorizer = joblib.load('vectorizer.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "modelo_regresion = joblib.load('regresion.pkl')\n",
    "label_binarizer = joblib.load('label_binarizer.pkl')\n",
    "\n",
    "def process_request(year, title, plot):\n",
    "    # Vectorizar el plot\n",
    "    plot_vectorized = vectorizer.transform([plot])\n",
    "    \n",
    "    # Normalizar el año\n",
    "    year_normalized = scaler.transform([[year]])\n",
    "    \n",
    "    # Concatenar las características\n",
    "    features = np.hstack((plot_vectorized.toarray(), year_normalized))\n",
    "    \n",
    "    # Predecir los géneros\n",
    "    prediccion = modelo_regresion.predict(features)\n",
    "    \n",
    "    # Decodificar la predicción\n",
    "    prediccion_decoded = label_binarizer.inverse_transform(prediccion)\n",
    "    \n",
    "    return prediccion_decoded[0]\n",
    "\n",
    "class GenresInfo(Resource):\n",
    "    @api.expect(parser)\n",
    "    def get(self):\n",
    "        args = parser.parse_args()\n",
    "        year = args['year']\n",
    "        title = args['title']\n",
    "        plot = args['plot']\n",
    "        \n",
    "        result = process_request(year, title, plot)\n",
    "        return {\n",
    "            'description': f\"Los géneros son: {', '.join(result)}\",\n",
    "            'result': result\n",
    "        }\n",
    "\n",
    "api.add_resource(GenresInfo, '/genres_info')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False, host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
